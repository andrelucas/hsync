#!/usr/bin/env python

# Simple sync-in-the-clear tool. Use SHA* and http to sync two
# directories using only HTTP GET.

from __future__ import print_function

from BaseHTTPServer import BaseHTTPRequestHandler
import grp
import hashlib
import logging
import optparse
import os.path
import pwd
from random import SystemRandom
import re
from stat import *
import sys
import urllib2
import urlparse

from exceptions import *
from filehash import *
from idmapper import *


log = logging.getLogger()

class URLMustBeOfTypeFileError(Exception): pass
class ContentsFetchFailedError(Exception): pass


def hashlist_generate(srcpath, opts, source_mode=True):
    '''
    Generate the haslist for the given path.

    srcpath - the top-level directory
    opts    - the optparse options dict

    Return a list of FileHash objects representing objects in the srcpath
    filesystem.

    If opts.trim_path is True, strip the srcpath from the filename in the
    hashlist. This makes it easier to work with relative paths.

    opts.no_ignore_dirs and opts.no_ignore_files disable the default
    behaviour, which is to ignore of common dirs (CVS, .git, .svn) and files
    (*~, *.swp).

    '''

    if os.path.exists(srcpath):
        if not os.path.isdir(srcpath):
            raise NonDirFoundAtDirLocationError(
                "'%s' found but is not a directory" % srcpath)
    else:
        os.mkdir(srcpath)

    hashlist = []

    if not opts.quiet:
        if source_mode:
            print("Scanning filesystem")
        else:
            print("Comparing filesystem")


    for root, dirs, files in os.walk(srcpath):

        if log.isEnabledFor(logging.DEBUG):
            logging.debug("os.walk: root %s dirs %s files %s", root, dirs, files)

        # See if the directory list can be pruned.
        if not opts.no_ignore_dirs:
            for dirname in dirs:
                for di in dirignore:
                    if di.search(dirname):
                        if source_mode and opts.verbose:
                            print("Skipping ignore-able dir %s" % dirname)
                        dirs.remove(dirname)

        # Likewise, handle the user's exclusions.
        if opts.exclude_dir:
            done_skip = False
            for dirname in opts.exclude_dir:
                if dirname in dirs:
                    if source_mode and opts.verbose:
                        print("Skipping manually-excluded dir %s" % dirname)
                    log.debug("Exclude dir '%s'", dirname)
                    dirs.remove(dirname)
                    done_skip=True
            if done_skip:
                log.debug("dirs now %s", dirs)


        # Handle directories.
        for dirname in dirs:
            fpath = os.path.join(root, dirname)
            fh = FileHash.init_from_file(fpath, trim=opts.trim_path, root=srcpath)
            if source_mode and opts.verbose:
                print("Add dir:  %s" % fpath)
            hashlist.append(fh)
            
        for filename in files:

            fpath = os.path.join(root, filename)

            if filename == opts.hash_file:
                log.debug("Skipping pre-existing hash file '%s'", opts.hash_file)
                continue

            skipped = False
            if not opts.no_ignore_files:
                for fi in fileignore:
                    if fi.search(fpath):
                        if source_mode and opts.verbose:
                            print("Ignore:  %s" % fpath)
                        skipped = True
                        break

            if skipped:
                continue

            log.debug("Add file: %s", fpath)
            if source_mode and opts.verbose:
                print("Add file: %s" % fpath)
            fh = FileHash.init_from_file(fpath, trim=opts.trim_path, root=srcpath)

            hashlist.append(fh)

    return hashlist


def sigfile_write(hashlist, abs_path, opts):

    if not opts.quiet:
        print("Generating signature file %s" % abs_path)


    log.debug("Writing hash file '%s'", abs_path)
    sigfile = open(abs_path, 'w')
    for fh in hashlist:
        print(fh.presentation_format(), file=sigfile)
    print("FINAL: %s" % (hash_of_hashlist(hashlist)), file=sigfile)
    sigfile.close()
    return True


def hash_of_hashlist(hashlist):
    '''
    Take a created hashlist and hash its digests and paths, to get
    a composite hash.
    '''

    md = hashlib.sha256()
    for fh in hashlist:
        md.update(fh.sha_hash().digest())

    return md.hexdigest()


def hashlist_to_dict(hashlist):
    '''
    Take a hashlist generated by generate_hashlist(), and return a dict keyed
    on the file path, with the hash as the value.
    '''
    hdict = {}
    for fh in hashlist:
        hdict[fh.fpath] = fh

    log.debug("hdict %s", hdict)
    return hdict


def hashlist_from_stringlist(strfile, opts):

    hashlist = []
    for l in strfile:
        if l.startswith("#"):
            pass # FFR
        if l.startswith("FINAL: "):
            pass # FFR
        else:
            fh = FileHash.init_from_string(l, opts.trim_path, root=opts.dest_dir)
            hashlist.append(fh)
    
    return hashlist


def hashlist_check(dstpath, src_hashlist, opts):
    '''
    Check the dstpath against the provided hashlist.

    Return a tuple (needed, notneeded, dst_hashlist), where needed is a list
    of filepaths that need to be fetched, and notneeded is a list of filepaths
    that are not present on the target, so may be removed. dst_hashlist is
    a list of FileHash objects for the destination path.

    '''

    src_fdict = hashlist_to_dict(src_hashlist)
    
    # Take the simple road. Generate a hashlist for the destination.
    dst_hashlist = hashlist_generate(dstpath, opts, source_mode=False)
    dst_fdict = hashlist_to_dict(dst_hashlist)

    direx = set()
    if opts.exclude_dir:
        direx = set(opts.exclude_dir)

    # Now compare the two dictionaries.
    needed = []
    excluded_dirs = set()

    for fpath, fh in [(k,src_fdict[k]) for k in sorted(src_fdict.keys())]:

        exclude = False

        # Process exclusions.
        if fh.is_dir and fpath in direx:
            log.debug("%s: Exclude dir", fpath)
            dpath = fpath.rstrip(os.sep) + os.sep # Make sure it ends in a slash.
            excluded_dirs.add(dpath)
            log.debug("Added exclusion dir: '%s'", dpath)
            exclude = True

        if not exclude: # No point checking twice.
            for exc in excluded_dirs:
                if fpath.startswith(exc):
                    log.debug("Excluded '%s': Under '%s'", fpath, exc)
                    exclude = True

        if exclude:
            continue

        if fpath in dst_fdict:

            # if src_fdict[fpath].can_compare(dst_fdict[fpath]):
            #     if src_fdict[fpath].compare_contents(dst_fdict[fpath]):
            #         log.debug("%s: present and hash verified", fpath)
            #     else:
            #         log.debug("%s: present but failed hash verify", fpath)
            #         if opts.verify_only:
            #             print "%s failed contents verification" % fpath
            #         fh.verification_failed = True
            #         needed.append(fh)

            # else:
            #     # Couldn't verify contents, assume it's needed.
            #     log.debug("%s: present, can't compare - assume needed", fpath)

            #     needed.append(fh)
            if not src_fdict[fpath].compare(dst_fdict[fpath],
                                            ignore_mode=opts.ignore_mode):
                log.debug("%s: needed", fpath)
                needed.append(fh)
                

        else:
            log.debug("%s: needed", fpath)
            needed.append(fh)
                
    not_needed = []
    for fpath, fh in dst_fdict.iteritems():
        if not fpath in src_fdict:
            log.debug("%s: not found in source", fpath)
            not_needed.append(fh)
        
    return (needed, not_needed, dst_hashlist)




def fetch_needed(needed, source, opts):
    '''
    Download/copy the necessary files from opts.source_url or opts.source_dir
    to opts.dest_dir.

    This is a bit fiddly, as it tries hard to get the modes right.
    '''

    r = SystemRandom()
    mapper = UidGidMapper()
    errorCount = 0

    if not source.endswith('/'):
        source += "/"

    for fh in needed:
        if log.isEnabledFor(logging.DEBUG):
            if fh.is_dir:
                log.debug("fetch_needed: dir %s", fh.fpath)
            else:
                log.debug("fetch_needed: %s", fh.fpath)

        
        source_url = urlparse.urljoin(source, fh.fpath)

        if fh.is_file:
            if not opts.quiet:
                print("Get file: %s" % fh.fpath)
            contents = fetch_contents(source_url, opts)
            if contents is None:
                if opts.fail_on_errors:
                    raise ContentsFetchFailedException(
                        "Failed to fetch '%s'" % source_url)

            else:
                chk = hashlib.sha256()
                chk.update(contents)
                if chk.hexdigest() != fh.hashstr:
                    log.warn("File '%s' failed checksum verification!", fh.fpath)
                    errorCount += 1
                    continue

                tgt_file = os.path.join(opts.dest_dir, fh.fpath)
                tgt_file_rnd = tgt_file + ".%08x" % r.randint(0, 0xfffffffff)
                log.debug("Will write to '%s'", tgt_file_rnd)
                if os.path.exists(tgt_file):
                    if os.path.islink(tgt_file):
                        raise ParanoiaError(
                            "Not overwriting existing symlink '%s' with file", tgt_file)
                    if os.path.isdir(tgt_file):
                        raise DirWhereFileExpectedError(
                            "Directory found where file expected at '%s'", tgt_file)

                # Dealing with file descriptors, use os.f*() variants.
                tgt = os.open(tgt_file_rnd, os.O_CREAT | os.O_EXCL | os.O_WRONLY, fh.mode)
                if tgt == -1:
                    raise OSOperationFailedError("Failed to open '%s'", tgt_file_rnd)

                expect_uid = mapper.get_uid_for_name(fh.user)
                expect_gid = mapper.get_gid_for_name(fh.group)

                filestat = os.stat(tgt_file_rnd)
                if filestat.st_uid != expect_uid or filestat.st_gid != expect_gid:
                    log.debug("Changing file %s ownership to %s/%s",
                                tgt_file_rnd, fh.user, fh.group)
                    if os.fchown(tgt, expect_uid, expect_gid) == -1:
                        log.warn("Failed to fchown '%s' to user %s group %s",
                                tgt_file_rnd, fh.user, fh.group)

                os.write(tgt, contents)
                os.close(tgt)
                log.debug("Moving into place: '%s' -> '%s'", tgt_file_rnd, tgt_file)
                if os.rename(tgt_file_rnd, tgt_file) == -1:
                    raise OSOperationFailedError("Failed to rename '%s' to '%s'",
                        tgt_file_rnd, tgt_file)

        elif fh.is_link:
            linkpath = os.path.join(opts.dest_dir, fh.fpath)

            if not os.path.exists(linkpath):
                log.debug("Creating symlink '%s'->'%s'",
                            linkpath, fh.link_target)
                if not opts.quiet:
                    print("Create symlink %s -> %s" %
                            (linkpath, fh.link_target))
                os.symlink(fh.link_target, linkpath)

            else:
                log.debug("Path '%s' exists in the filesystem", linkpath)
                if not os.path.islink(linkpath):
                    raise NonLinkFoundAtLinkLocationError(
                        "Non-symlink found where we want a symlink ('%s')",
                        linkpath)

                else:
                    # Symlink found. Check it.
                    curtgt = os.readlink(linkpath)        
                    # Create or move the symlink.
                    if curtgt != fh.link_target:
                        log.debug("Moving symlink '%s'->'%s'",
                                     linkpath, dh.link_target)
                        if not opts.quiet:
                            print("Move symlink %s -> %s" %
                                    (linkpath, fh.link_target))                       
                        os.symlink(fh.link_target, linkpath)

            expect_uid = mapper.get_uid_for_name(fh.user)
            expect_gid = mapper.get_gid_for_name(fh.group)

            lstat = os.lstat(linkpath)
            if lstat.st_uid != expect_uid or lstat.st_gid != expect_gid:
                log.debug("Changing link '%s' ownership to %s/%s",
                    linkpath, expect_uid, expect_gid)
                os.lchown(linkpath, expect_uid, expect_gid)

            if lstat.st_mode != fh.mode:
                log.debug("Changing link '%s' mode to %06o",
                            linkpath, fh.mode)
                os.lchmod(linkpath, fh.mode)

        elif fh.is_dir:
            tgt_dir = os.path.join(opts.dest_dir, fh.fpath)
            if os.path.exists(tgt_dir):
                log.debug("Path '%s' exists in the filesystem", tgt_dir)
                if not os.path.isdir(tgt_dir):
                    raise NonDirFoundAtDirLocationError(
                        "Non-directory found where we want a directory ('%s')",
                        tgt_dir)
            else:
                log.debug("Creating directory '%s'", tgt_dir)
                if not opts.quiet:
                    print("Create dir: %s" % fh.fpath)
                os.mkdir(tgt_dir, fh.mode)

            # Dealing with a directory on the filesystem, not an fd - use the
            # regular os.*() variants, not the os.f*() methods.

            # Change modes and ownership.
            expect_uid = mapper.get_uid_for_name(fh.user)
            expect_gid = mapper.get_gid_for_name(fh.group)

            dstat = os.stat(tgt_dir)
            if dstat.st_uid != expect_uid or dstat.st_gid != expect_gid:
                log.debug("Changing dir %s ownership to %s/%s",
                            tgt_dir, fh.user, fh.group)
                os.chown(tgt_dir, expect_uid, expect_gid)

            if dstat.st_mode != fh.mode:
                log.debug("Changing dir %s mode to %06o", tgt_dir, fh.mode)
                os.chmod(tgt_dir, fh.mode)

    if errorCount == 0:
        if not opts.quiet:
            print("Fetch completed")
        log.debug("Fetch completed successfully")
        return True

    else:
        log.warn("Fetch failed with %d errors", errorCount)
        return False           
                

def delete_not_needed(not_needed, target, opts):
    '''
    Remove files from the destination that are not present on the source.
    '''
    dirs_to_delete = []
    errorCount = 0

    for fh in not_needed:
        if fh.is_dir:
            log.debug("Saving dir '%s' for later deletion")
            dirs_to_delete.append(fh)

        else:
            fullpath = os.path.join(target, fh.fpath)
            log.debug("delete_not_needed: %s", fullpath)
            if not opts.quiet:
                print("Remove file: %s" % fh.fpath)
            os.remove(fullpath)

    if dirs_to_delete:
        # Sort the delete list by filename, then reverse so it's depth-
        # first.
        dirs_to_delete.sort(key=lambda x: x.fpath, reverse=True)
        for d in dirs_to_delete:
            fullpath = os.path.join(target, d.fpath)
            if not opts.quiet:
                print("Remove dir: %s" % d.fpath)
            log.debug("Deleting directory '%s'", fullpath)
            os.rmdir(fullpath)

    if errorCount:
        log.warn("Delete failed with %d errors", errorCount)
        return False

    return True


def fetch_contents(fpath, opts, root='', no_trim=False):
    '''
    Wrap a fetch, which may be from a file or URL depending on the options.

    Returns None on a 404, re-raises the Exception otherwise.
    '''

    fullpath = fpath

    if not no_trim and opts.trim_path and root:
        fullpath = os.path.join(opt.source_url, fpath)

    log.debug("fetch_contents: %s", fullpath)

    try:
        url = urllib2.urlopen(fullpath)
        contents = url.read()

    except urllib2.HTTPError, e:
        if e.code == 404:
            resp = BaseHTTPRequestHandler.responses
            log.warn("Failed to retrieve '%s': %s", fullpath, resp[404][0])
            return None
        else:
            raise(e)

    return contents


def _cano_url(url, slash=False):
    log.debug("_cano_url: %s", url)
    up = urlparse.urlparse(url)
    log.debug("urlparse: %s", up.geturl())
    if up.scheme == '':
        url = 'file://' + url
        log.debug("Add scheme, URL=%s", url)
    if slash and not url.endswith("/"):
        url += "/"
    return url


def main(cmdargs):
    p = optparse.OptionParser()

    send = optparse.OptionGroup(p, "Send-side options")
    send.add_option("-S", "--source-dir",
        help="Specify the source directory")
    send.add_option("--no-trust-timestamps",
        help="Don't use timestamps to avoid re-scanning files")
    p.add_option_group(send)

    recv = optparse.OptionGroup(p, "Receive-side options")
    recv.add_option("-D", "--dest-dir",
        help="Specify the destination directory")
    recv.add_option("-u", "--source-url",
        help="Specify the data source URL")
    recv.add_option("--no-write-hashfile", action="store_true",
        help="Don't write a signature file after sync")
    recv.add_option("-P", "--progress", action="store_true",
        help="Show download progress")
    recv.add_option("--ignore-mode", action="store_true",
        help="Ignore differences in file modes")
    recv.add_option("--http-user",
        help="Specify the HTTP auth user")
    recv.add_option("--http-pass",
        help="Specify the HTTP auth password")
    recv.add_option("--http-auth-type", default='basic',
        help="Specify HTTP auth type (basic|digest) "
            "[default: %default]")
    recv.add_option("--proxy-url",
        help="Specify the proxy URL to use")
    p.add_option_group(recv)

    recv.add_option("-U", "--signature-url",
        help="Specify the signature file's URL [default: <source_url>/HSYNC.SIG]")

    meta = optparse.OptionGroup(p, "Other options")
    meta.add_option("-V", "--verify-only", action="store_true",
        help="Verify only, do not transfer or delete files")
    meta.add_option("--fail-on-errors", action="store_true",
        help="Fail on any error. Default is to try to carry on")
    meta.add_option("--hash-file", default="HSYNC.SIG",
        help="Specify the hash filename [default: %default]")
    meta.add_option("--no-ignore-dirs", action="store_true",
        help="Don't trim common dirs such as .git, .svn and CVS")
    meta.add_option("--no-ignore-files", action="store_true",
        help="Don't trim common ignore-able files such as *~ and *.swp")
    meta.add_option("--no-trim-path", action="store_false",
        default=True, dest='trim_path',
        help="Don't trim the top-level path from filenames. It's safer to "
            "leave this well alone.")
    meta.add_option("-X", "--exclude-dir", action="append",
        help="Specify a directory path (relative to the root) to ignore. "
            "On the server side, this simply doesn't checksum the file, "
            "which has the effect of rendering it invisible (and deletable!)"
            "on the client side. On the client side, it prevents processing "
            "of the path.")

    p.add_option_group(meta)

    output = optparse.OptionGroup(p, "Output options")

    output.add_option("-v", "--verbose", action="store_true",
        help="Enable verbose output")
    output.add_option("-d", "--debug", action="store_true",
        help="Enable debugging output")
    output.add_option("-q", "--quiet", action="store_true",
        help="Reduce output further")
    p.add_option_group(output)

    (opt, args) = p.parse_args(args=cmdargs)

    if opt.quiet and (opt.verbose or opt.debug):
        log.error("It doesn't make sense to mix quiet and verbose options")
        return False

    level = logging.WARNING
    if opt.verbose:
        level = logging.INFO
    if opt.debug:
        level = logging.DEBUG
        opt.verbose = True

    logging.basicConfig(level=level)
    log = logging.getLogger()

    # As soon as logging is configured, say what we're doing.
    if log.isEnabledFor(logging.DEBUG):
        log.debug("main: args %s", cmdargs)

    if opt.source_dir and opt.dest_dir:
        log.error("Send-side and receive-side options can't be mixed")
        return False

    if log.isEnabledFor(logging.DEBUG):
        log.debug("hashlib.algorithms: %s", hashlib.algorithms)

    if not 'sha256' in hashlib.algorithms:
        log.error("No SHA256 implementation in hashlib!")
        return False

    # Send-side.
    if opt.source_dir:

        hashlist = hashlist_generate(opt.source_dir, opt)
        if hashlist is not None:

            abs_hashfile = None
            
            if opt.signature_url:
                hashurl = _cano_url(opt.signature_url)
                log.debug("Explicit signature URL '%s'", hashurl)
                up = urlparse.urlparse(hashurl)
                if up.scheme != 'file':
                    raise URLMustBeOfTypeFileError(
                        "Signature URL '%s' must be a local file", hashurl)
                abs_hashfile = up.path
                log.debug("Explicit signature file '%s'", abs_hashfile)

            else:
                hashfile = 'HSYNC.SIG'
                if opt.hash_file:
                    hashfile = opt.hash_file

                abs_hashfile = os.path.join(opt.source_dir, hashfile)
                log.debug("Synthesised hash file location: '%s'", abs_hashfile)

            if not sigfile_write(hashlist, abs_hashfile, opt):
                log.error("Failed to write signature file '%s'",
                    os.path.join(opt.source_dir, opt.hash_file))
                return False
            
            return True

        else:
            log.error("Send-side generate failed")
            return False

    # Receive-side.
    elif opt.dest_dir:

        if opt.source_url is None:
            log.error("-u/--source-url must be defined for -D/--dest-dir mode")
            return False

        if opt.http_auth_type != 'digest' and opt.http_auth_type != 'basic':
            log.error("HTTP auth type must be one of 'digest' or 'basic'")
            return False

        if opt.http_user:
            log.debug("Configuring HTTP authentication")
            if not opt.http_pass:
                log.error("HTTP proxy password must be specified")

            pwmgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
            pwmgr.add_password(None, opt.source_url,
                                opt.http_user, opt.http_pass)
            auth_opener = None
            if opt.http_auth_type == 'digest':
                log.debug("Configuring digest authentication")
                auth_opener = urllib2.build_opener(urllib2.DigestAuthHandler(pwmgr))

            else:
                log.debug("Configuring basic authentication")
                auth_opener = urllib2.build_opener(urllib2.HTTPBasicAuthHandler(pwmgr))

            urllib2.install_opener(auth_opener)

        if opt.proxy_url:
            log.debug("Configuring proxy")
            

        hashurl = None
        if opt.signature_url:
            hashurl = _cano_url(opt.signature_url)
            log.debug("Explicit signature URL '%s'", hashurl)

        else:
            hashurl = _cano_url(opt.source_url, slash=True) + opt.hash_file
            log.debug("Synthesised signature URL '%s'", hashurl)

        hashfile_contents = fetch_contents(hashurl, opt)

        if hashfile_contents is None:
            # We're not coming back from this.
            log.error("Failed to retrieve signature file from '%s", hashurl)
            return False  

        strfile = hashfile_contents.splitlines()

        opt.source_url = _cano_url(opt.source_url, slash=True)
        log.debug("Source url '%s", opt.source_url)

        src_hashlist = hashlist_from_stringlist(strfile, opt)

        # Calculate the differences to the local filesystem.
        (needed, not_needed, dst_hashlist) = hashlist_check(opt.dest_dir,
                                                        src_hashlist, opt)


        if opt.verify_only:
            # Give a report if we're verbose.
            if opt.verbose:
                for fh in needed:
                    print("Needed: %s" % fh.fpath)
                for fh in not_needed:
                    print("Needs delete: %s" % fh.path)

            if needed or not_needed:
                return False
            else:
                # True ('verified') means 'nothing to do'.
                return True
        
        else:
            if (not fetch_needed(needed, opt.source_url, opt) or 
                not delete_not_needed(not_needed, opt.dest_dir, opt)):
                log.error("Sync failed")
                return False

            if not opt.no_write_hashfile and dst_hashlist is not None:
                # FFR may need to put this elsewhere.
                abs_hashfile = os.path.join(opt.dest_dir, opt.hash_file)
                if not sigfile_write(dst_hashlist, abs_hashfile, opt):
                    log.error("Failed to write signature file '%s'",
                                os.path.join(opt.source_dir, opt.hash_file))
                return False

            return True

    else:
        print("Nothing to do!")
        return True


def csmain():
    if not main(sys.argv[1:]):
        sys.exit(1)


if __name__ == '__main__':
    csmain()        
